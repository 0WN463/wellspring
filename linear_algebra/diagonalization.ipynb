{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e56de84-5f41-4dcf-9ab8-cc2ada2c2747",
   "metadata": {
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\newcommand{theorem}{\\textbf{Theorem: }}\n",
    "\\newcommand{proof}{\\textbf{Proof: }}\n",
    "\\newcommand{lemma}{\\textbf{Lemma: }}\n",
    "\\newcommand{corollary}{\\textbf{Corollary: }}\n",
    "\\newcommand{prop}{\\textbf{Proposition: }}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7f920-f84b-411a-a5b1-ba15b801e0cb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{arr}{\\mathbf}\n",
    "\\newcommand{inv}{^{-1}}\n",
    "\\newcommand\\mat[1]{\\begin{pmatrix}#1\\end{pmatrix}} \n",
    "\\newcommand\\det[1]{\\left| #1\\right|} \n",
    "\\newcommand\\norm[1]{\\lVert #1\\rVert} \n",
    "\\newcommand\\set[1]{\\left\\{#1\\right\\}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809b4aac-d214-40c6-b3c7-be9f098e9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from module.matrix import mult, inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305e841-4302-4c83-b1dc-924f5764d18b",
   "metadata": {},
   "source": [
    "# Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b15ef-d01e-4b40-8f62-c47689001e70",
   "metadata": {},
   "source": [
    "A square matrix $\\arr A$ is **diagonalizable** if there exists an invertible matrix $\\arr P$ such that $\\arr P \\inv \\arr A \\arr P = \\arr D$ is a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1d834-aaad-48d5-b3fa-904213dbc6b5",
   "metadata": {},
   "source": [
    "In other words, $\\arr A = \\arr {PDP} \\inv$, for some diagonal matrix $\\arr D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de55b9f-e376-4bc7-9daf-610a40b961e0",
   "metadata": {},
   "source": [
    "$\\lemma$ $\\arr D$ will contain the eigenvalues of $\\arr A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4401a6-437d-45a9-a3b0-44f94fcf7e83",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary style=\"color: blue\">$\\proof$ (Click to expand)</summary>\n",
    "    <div style=\"background: aliceblue\">\n",
    "        We consider the characteristic polynomial of $\\arr A$:\n",
    "        $$\n",
    "        \\begin{align}\n",
    "        \\det{x \\arr I - \\arr A} &= \\det{x \\arr I - \\arr {PDP}\\inv} \\\\\n",
    "        &= \\det{x \\arr {PP} \\inv - \\arr {PDP} \\inv} \\\\\n",
    "        &= \\det{\\arr P (x \\arr I - \\arr D) \\arr P \\inv} \\\\\n",
    "        &= \\det{\\arr P} \\det {x \\arr I - \\arr D} \\det {\\arr P \\inv} \\\\\n",
    "        &= \\det{x \\arr I - \\arr D}\n",
    "        \\end{align}\n",
    "        $$\n",
    "        Hence, $\\arr A$ and $\\arr D$ have the same characteristic polynomial, and hence the same eigenvalues.\n",
    "        Since $\\arr D$ is diagonal, we know that its (diagonal) entries are its eigenvalues.\n",
    "        $$QED$$\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ba003-7e01-4a77-a587-bc5b20702972",
   "metadata": {},
   "source": [
    "$\\theorem$ Given a square matrix $\\arr A$, $\\arr A$ is diagonalizable if and only if there exists a basis $\\set{\\arr u_1, \\dots, \\arr u_n}$, where $\\arr u_i \\in \\mathbb R^n$ are all eigenvectors of $\\arr A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46780a60-3ca2-45fe-b706-c59ef9ce8cb1",
   "metadata": {},
   "source": [
    "Proof is omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302842a2-7aa8-4f3a-a421-0e2a3c1a6980",
   "metadata": {},
   "source": [
    "In other words, if $\\arr A$ is diagonalizable, it can be expressed as $\\arr {PDP} \\inv$, where $\\arr D$ is a diagonal entries with its eigenvalues, and $\\arr P$ which are horizontally stacked columns of the eigenvectors of $\\arr A$, and the eigenvector of each column correspond to the eigenvector in the same column of $\\arr D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d2d6d-11ad-450b-a817-141eb9ca3894",
   "metadata": {},
   "source": [
    "**Example** \n",
    "\n",
    "Given $\\arr A = \\mat{1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 2}$.\n",
    "\n",
    "We can compute its eigenvalues to be $0$ and $2$.\n",
    "\n",
    "The bases are $E_0 = \\set{\\mat{-1 \\\\ 1 \\\\ 0}}, E_2 = \\set{\\mat{1 \\\\ 1 \\\\0},\\mat{0 \\\\ 0 \\\\ 1}}$.\n",
    "\n",
    "Thus, we simply stack the columns to get $\\arr P = \\mat{-1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 1}$.\n",
    "\n",
    "And $\\arr D = \\mat{0 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 2}$.\n",
    "\n",
    "Putting it together, we get $$\\arr A =  \\mat{-1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 1}\\mat{0 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 2} \\mat{-1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 1} \\inv$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f032035a-e89a-49c7-889d-5f3d71ce653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([-1, 1, 0, 1, 1, 0, 0, 0, 1]).reshape((3, 3))\n",
    "D = np.diag([0, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93523e39-1c96-4d6a-a4c3-94568c37b7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [0., 0., 2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult(P, mult(D, inv(P)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61075b4c-0cec-459c-b0c2-45895d01023b",
   "metadata": {},
   "source": [
    "For $\\arr A = \\mat{1 & 2 \\\\ 0 & 1}$.\n",
    "We can see that the eigenvalue is $\\lambda = 1$ with multiplicity of 2.\n",
    "However, there is only 1 eigenvector associated with the eigenvalue, $\\mat{ 1 \\\\ 0}$, and hence we are unable to diagonalize $\\arr A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9f5f8d-5a73-4e51-a032-f1a763e370f7",
   "metadata": {},
   "source": [
    "$\\theorem$ The geometric multiplicity of any eigenvector is at most its algebraic multiplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65fb033-bf9b-44e2-b28c-13f0aa7b0831",
   "metadata": {},
   "source": [
    "$\\theorem$ $\\arr A$ is diagonalizable if and only if the geometric multiplicity of all eigenvectors is equals to its algebraic multiplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16c8a3-deb5-4223-a970-abe3a3a518a4",
   "metadata": {},
   "source": [
    "Hence, it tells us there that are 2 requirements for a matrix to be diagonalizable:\n",
    "1. It has to have sufficient number of (real) eigenvalues, so that we can fill up $\\arr D$.\n",
    "2. It has to have sufficient number of eigenvectors, so that we can fill up $\\arr A$.\n",
    "    * This is related to the geometric multiplicity being equals to the algebraic multiplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcec06b-6f2c-4fd2-9176-28a1baffe964",
   "metadata": {},
   "source": [
    "$\\corollary$ Any square matrix of order $n$ with $n$ distinct eigenvalues is diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62179269-1f44-48ef-9105-31afe197ce06",
   "metadata": {},
   "source": [
    "## Orthogonal diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5957a19-17ac-4534-9f9f-6043efe22197",
   "metadata": {},
   "source": [
    "A square matrix is known as an **orthogonal matrix** if $\\arr A^T = \\arr A \\inv$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51791f-951a-4c8a-9dcb-b50e767105f8",
   "metadata": {},
   "source": [
    "$\\theorem$ The following statements are equivalent, for $\\arr A$, a square matrix of $\\arr n$:\n",
    "1. $\\arr A$ is orthogonal\n",
    "2. The columns of $\\arr A$  forms a orthonormal basis for $\\mathbb R^n$\n",
    "2. The rows of $\\arr A$  forms a orthonormal basis for $\\mathbb R^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6dffb-3796-43d3-968e-a0489d29466e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary style=\"color: blue\">$\\proof$ (Click to expand)</summary>\n",
    "    <div style=\"background: aliceblue\">\n",
    "        We express $$\\arr A = \\mat{\\arr c_1 & \\dots & \\arr c_n}$$\n",
    "        Now notice that $\\arr A ^T \\arr A = \\mat{\\arr c_1^T \\\\ \\vdots \\\\ \\arr c_n^T} \\mat{\\arr c_1 & \\dots & \\arr c_n}$\n",
    "        <br>\n",
    "        Hence, the $ij$-th entry of $\\arr A^T \\arr A$ is $c_i^T c_j =  c_i \\cdot c_j$.\n",
    "        <br>\n",
    "        Hence, $\\arr A ^T = \\arr A \\inv \\Leftrightarrow \\arr A^T \\arr A = \\arr I \\Leftrightarrow c_i \\cdot c_j = \\begin{cases} 1, \\quad i = j \\\\ 0, \\quad i \\neq j\\end{cases} \\Leftrightarrow $ columns of $\\arr A$ is an orthonormal basis.\n",
    "        <br>\n",
    "        We have proven statement 1 to 2, and can do similarly for 1 to 3.\n",
    "        $$QED$$\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d595569e-6eef-4d3f-b2f5-a77f32927371",
   "metadata": {},
   "source": [
    "A square matrix $\\arr A$ is **orthogonally diagonalizable** if \n",
    "$$\n",
    "\\arr A = \\arr {PDP}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b26c4a-4061-4ae2-9edf-ee88317748af",
   "metadata": {},
   "source": [
    "$\\theorem$ A square matrix is orthogonally diagonalizable if and only if it is symmetric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbb745-6ea7-43cc-b76c-e837476f1efb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary style=\"color: blue\">$\\proof$ (Click to expand)</summary>\n",
    "    <div style=\"background: aliceblue\">\n",
    "        Suppose that it is orthogonally diagonalizable, then\n",
    "        $$\n",
    "        \\arr A ^T = (\\arr {PDP}^T)^T = (\\arr P^T)^T \\arr D^T \\arr P^T = \\arr P \\arr D \\arr P^T = \\arr A\n",
    "        $$\n",
    "        Hence it is symmetric.\n",
    "        The proof for the converse is omitted as it is beyond the scope of this course.\n",
    "        $$QED$$\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a694977-7808-4e2c-a31f-7c4e73c9d5cf",
   "metadata": {},
   "source": [
    "To orthogonally diagonalize a matrix, we simply do similar to diagonalizing a matrix, except that for each eigenvalue, we perform the [Gram-Schmidt process](./orthogonal_projection.ipynb#Gram-Schmidt-process) on the associated eigenvectors to obtain an orthonormal basis for the eigenspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c320a3-71d3-4e02-bf5d-af9864b8ef39",
   "metadata": {},
   "source": [
    "**Example** \n",
    "\n",
    "Using our previous example of $\\arr A = \\mat{1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 2}$.\n",
    "\n",
    "The bases are $E_0 = \\set{\\mat{-1 \\\\ 1 \\\\ 0}}, E_2 = \\set{\\mat{1 \\\\ 1 \\\\0},\\mat{0 \\\\ 0 \\\\ 1}}$.\n",
    "\n",
    "The orthonormal bases are $E_0 = \\frac{1}{\\sqrt 2} \\set{\\mat{-1 \\\\ 1 \\\\ 0}}, E_2 = \\set{\\frac{1}{\\sqrt 2}\\mat{1 \\\\ 1 \\\\0},\\mat{0 \\\\ 0 \\\\ 1}}$.\n",
    "\n",
    "Putting it together, we get $$\\arr A =  \\mat{-\\frac{1}{\\sqrt 2} & \\frac{1}{\\sqrt 2} & 0 \\\\ \\frac{1}{\\sqrt 2} & \\frac{1}{\\sqrt 2} & 0 \\\\ 0 & 0 & 1}\\mat{0 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 2}\\mat{-\\frac{1}{\\sqrt 2} & \\frac{1}{\\sqrt 2} & 0 \\\\ \\frac{1}{\\sqrt 2} & \\frac{1}{\\sqrt 2} & 0 \\\\ 0 & 0 & 1} ^T $$.\n",
    "\n",
    "($\\arr P$ happened to be symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3fa1dd-bf07-4bdf-ba15-97378ab155ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.70710678,  0.70710678,  0.        ],\n",
       "        [ 0.70710678,  0.70710678,  0.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ]]),\n",
       " array([[-0.70710678,  0.70710678,  0.        ],\n",
       "        [ 0.70710678,  0.70710678,  0.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isqrt = 1/np.sqrt(2)\n",
    "P = np.array([-isqrt, isqrt, 0, isqrt, isqrt, 0, 0, 0, 1]).reshape((3 , 3))\n",
    "P, inv(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7914e-bc5a-426a-812f-ec4b5401e75b",
   "metadata": {},
   "source": [
    "Indeed, we see that $\\arr P ^T = \\arr P \\inv$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eab1f3a-a5a6-4a97-a532-181e1b974957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [0., 0., 2.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.diag([0, 2, 2])\n",
    "mult(P, mult(D, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f47a03-a27a-40a8-ab56-e10c47c34a19",
   "metadata": {},
   "source": [
    "And we can see that $\\arr A = \\arr{PDP}^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f89e2-2692-4cd1-a80d-1af71b62fc40",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6e817-6c76-4a8a-a57b-991edeab75e2",
   "metadata": {},
   "source": [
    "### Matrix exponentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733b931-2874-4eca-95dc-915c14f3ed18",
   "metadata": {},
   "source": [
    "We can use diagonalization to perform raising a matrix to a power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f93e45-2a26-44e1-9852-30346e1e358c",
   "metadata": {},
   "source": [
    "$\\lemma$ If $\\arr A = \\arr {PDP} \\inv$, then $\\arr A^m = \\arr P \\arr D^m \\arr P \\inv$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c555e-2009-4962-ac18-a8e52a6a83f0",
   "metadata": {},
   "source": [
    "$\\lemma$ Let the diagonal entries $\\arr D$ be $d_1, \\dots, d_n$, then $\\arr D^m$ is also diagonal, with entries $d_1 ^m, \\dots, d_n^m$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c68aa-6107-44ef-8dd8-d51c49ed387a",
   "metadata": {},
   "source": [
    "Hence, we have found an easy way to compute a large power of a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bfb2e-dff6-400e-8e28-c8e11f87f607",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec797c-8da0-431c-97ee-1ff4022269f4",
   "metadata": {},
   "source": [
    "Using our previous example of $\\arr A = \\mat{1 &  1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f94f6-07ae-44ab-b168-e60cdc08028e",
   "metadata": {},
   "source": [
    "Suppose that we want to compute $\\arr A ^{20}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec8659-69bd-4946-8c92-22dc751bbd9d",
   "metadata": {},
   "source": [
    "Rather than performing many matrix multiplications, we can instead compute\n",
    "$$\n",
    "\\arr A ^{20} = \\arr P \\arr D^{20} \\arr P \\inv\n",
    "= \\mat{-1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 1}\\mat{0 & 0 & 0 \\\\ 0 & 2^{20} & 0 \\\\ 0 & 0 & 2^{20}} \\mat{-1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 1} \\inv\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c8d1719-b502-4497-8b68-d1fc17413e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 524288.,  524288.,       0.],\n",
       "       [ 524288.,  524288.,       0.],\n",
       "       [      0.,       0., 1048576.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.array([-1, 1, 0, 1, 1, 0, 0, 0, 1]).reshape((3, 3))\n",
    "D20 = np.diag([0, 2**20, 2**20])\n",
    "mult(P, mult(D20, inv(P)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f140ee1-8d3e-4475-9731-f73bc7779ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 524288.,  524288.,       0.],\n",
       "       [ 524288.,  524288.,       0.],\n",
       "       [      0.,       0., 1048576.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 20\n",
    "\n",
    "A = np.array([1,1, 0, 1, 1, 0, 0, 0, 2]).reshape((3, 3))\n",
    "Am = A\n",
    "for _ in range(1, m):\n",
    "    Am = mult(Am, A)\n",
    "    \n",
    "Am"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375bbca-c03b-4ebe-bd92-d469784694fd",
   "metadata": {},
   "source": [
    "Indeed, we get the same results when we use our diagonalization and when we perform the repeated multiplications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89616e5-152b-4ccc-83a7-5d73ba92f3d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In fact, matrix exponentiation usually props up when we are working with recursive formulas, such as linear recurrence or Markov chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d5a27-ea7f-447d-8706-6eceb6ced416",
   "metadata": {},
   "source": [
    "#### Linear recurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aace5bf-0a04-464d-a203-8cf112d96a64",
   "metadata": {},
   "source": [
    "The Fibonacci sequence is as follows:\n",
    "$$\n",
    "(0), 1, 1, 2, 3, 5, 8, 13, \\dots\n",
    "$$\n",
    "where each element is the sum of the previous two.\n",
    "(Note that $a_0 = 0$, but the start of the sequence is $a_1 = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391486c-1940-4be1-8d6e-742b9bc9c5a5",
   "metadata": {},
   "source": [
    "We can represent it as the following matrix equation:\n",
    "\n",
    "$$\n",
    "\\mat{a_n \\\\ a_{n+1}} = \\mat{0 & 1\\\\ 1 & 1}\\mat{a_{n-1} \\\\ a_n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a40ced-c0e8-4117-a6ca-8ca6d0266564",
   "metadata": {},
   "source": [
    "Notice that $\\mat {a_n \\\\ a_{n+1}} = \\mat{0 & 1 \\\\ 1 & 1}^n \\mat{0 \\\\ 1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2891f-09ac-44aa-b5ab-f331933df9d7",
   "metadata": {},
   "source": [
    "Diagonalizing $\\arr A = \\mat{0 & 1\\\\ 1 & 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b4ca7-98af-42ac-9787-e89a7d5fbcbe",
   "metadata": {},
   "source": [
    "$char (\\arr A) = x(x-1) -1 = x^2 - x -1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237ed53-ef27-470d-b183-7f67ee69e168",
   "metadata": {},
   "source": [
    "The eigenvalues are $\\lambda_a = \\frac{1 + \\sqrt 5}{2}, \\lambda_b = \\frac{1 - \\sqrt 5}{2}$, with the eigenvectors of $\\mat{1 \\\\ \\lambda _a}, \\mat{1 \\\\ \\lambda_b}$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72975689-0712-4006-bdf8-dd19c5a3799d",
   "metadata": {},
   "source": [
    "Hence, $\\arr A = \\arr {PDP} \\inv = \\mat{1 & 1 \\\\ \\lambda_a & \\lambda_b} \\mat{\\lambda _a & 0 \\\\ 0 & \\lambda _b}\\mat{1 & 1 \\\\ \\lambda_a & \\lambda_b}\\inv$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83c573-c354-4a18-a91e-dadd6d78f3d6",
   "metadata": {},
   "source": [
    "Thus, $\\arr A^n \\mat{0 \\\\ 1} = \\arr {PDP} \\inv = \\mat{1 & 1 \\\\ \\lambda_a & \\lambda_b} \\mat{\\lambda _a^n & 0 \\\\ 0 & \\lambda _b^n}\\mat{1 & 1 \\\\ \\lambda_a & \\lambda_b}\\inv \\mat{0 \\\\1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e045b9-a0fb-411e-a634-f9a8f387561d",
   "metadata": {},
   "source": [
    "Expanding the first row, we get that \n",
    "$$\n",
    "a_n = \\frac{\\lambda _a ^n - \\lambda _b ^n}{\\lambda_a - \\lambda_b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "822c46db-82fd-4efb-b4ac-0df27786db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12586269025.00002"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la = (1 + np.sqrt(5)) /2\n",
    "lb = (1 - np.sqrt(5)) /2\n",
    "\n",
    "n = 50\n",
    "(la ** n - lb **n)/(la - lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6883048-9209-44ba-b9f4-9b1651b9800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12586269025"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(n):\n",
    "    a, b = 1, 1\n",
    "    for _ in range(1, n):\n",
    "        a, b = b, a + b\n",
    "        \n",
    "    return a\n",
    "f(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5dd4ff-0097-49a8-8fd8-21cc36a8826e",
   "metadata": {},
   "source": [
    "Indeed, our close form formula yielded the same answer (albeit with some floating point inaccuracies) as the iterative solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
